Long Quiz: Advanced NLP Techniques & LLMs

Part A [10 x 3 points = 30] : Multiple Choice Questions (MCQs)

What is the primary advantage of Zero-Shot Learning (ZSL) in LLMs?
A. Requires labeled training data
B. Can perform tasks without prior training on specific data
C. Only works with small datasets
D. Eliminates the need for embeddings

Answer: B

How does Few-Shot Learning (FSL) differ from ZSL?
A. Uses a few labeled examples for adaptation
B. Requires a full dataset for training
C. Eliminates the need for tokenization
D. Works only with rule-based models

Answer: A

Which prompting strategy breaks down complex tasks into logical reasoning steps?
A. Zero-Shot Learning
B. Chain of Thought (CoT)
C. Direct Instruction
D. Token Splitting

Answer: B

What is a key feature of the ReAct prompting strategy?
A. Reinforces responses with external memory retrieval
B. Uses predefined answer templates
C. Ignores previously generated tokens
D. Reduces the need for fine-tuning

Answer: A

How does Direct Signal Processing (DSP) enhance NLP models?
A. Improves noise filtering in token embeddings
B. Enables data augmentation for LLM training
C. Speeds up inference time by avoiding retraining
D. Converts text input into binary representations

Answer: A

What is the goal of instruction tuning in LLMs?
A. Fine-tuning models using natural language instructions
B. Replacing self-attention with rule-based logic
C. Converting images into text prompts
D. Enhancing dataset augmentation strategies

Answer: A

Which orchestration method helps combine multiple LLMs to improve response quality?
A. Model stacking
B. Prompt chaining
C. Token pruning
D. Neural pruning

Answer: B

What is the role of Retrieval-Augmented Generation (RAG)?
A. Reduces token redundancy in model outputs
B. Integrates external data retrieval into response generation
C. Eliminates parameter tuning
D. Forces the model to ignore pre-training knowledge

Answer: B

Why are LLM Guardrails necessary?
A. Prevents hallucinations and biases in generated text
B. Eliminates the need for embeddings
C. Enhances dataset generation speed
D. Reduces tokenization complexity

Answer: A

What is a primary function of LLM Agents?
A. Automates decision-making using LLM outputs
B. Reduces the number of transformer layers
C. Eliminates the use of token embeddings
D. Limits model generalization capabilities

Answer: A

Part B [4 x 2 points = 8] : Multiple Choice Questions (MCQs)

How does parameter-efficient fine-tuning (PEFT) benefit LLM training?
A. Reduces memory consumption while adapting models
B. Eliminates the need for fine-tuning altogether
C. Increases the number of required training parameters
D. Speeds up model inference by skipping token processing

Answer: A

What challenge does RAG help mitigate in LLMs?
A. Limited contextual awareness due to static training data
B. Reduces computation time during training
C. Improves text generation randomness
D. Prevents overfitting to large datasets

Answer: A

Which technique can prevent harmful LLM outputs?
A. Safety-driven Guardrails
B. Token Splitting
C. Reducing embedding size
D. Using smaller training datasets

Answer: A

How does an LLM agent differ from a standard chatbot?
A. Uses decision-making frameworks beyond simple text generation
B. Eliminates the need for external training data
C. Reduces model inference time by 50%
D. Works only with structured datasets

Answer: A

Part C [2 x 6 points = 12]: MCQs with Explanation

Why is Chain of Thought (CoT) prompting useful for complex reasoning tasks?
A. It helps break problems into smaller, logical steps before generating an answer
B. It reduces token redundancy during inference
C. It improves model latency by compressing outputs
D. It eliminates the need for instruction fine-tuning

Answer: A
Explanation: CoT enables LLMs to handle multi-step reasoning tasks by structuring responses logically.

How do LLM Guardrails improve ethical AI usage?
A. By filtering unsafe or biased model outputs in real-time
B. By increasing the number of training parameters
C. By limiting model fine-tuning capabilities
D. By forcing the model to ignore zero-shot tasks

Answer: A
Explanation: LLM Guardrails implement safety measures to prevent harmful or unethical responses from AI models.

